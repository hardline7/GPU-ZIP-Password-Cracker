# GPU ZIP Password Cracker

NVIDIA GPUë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ ZIP íŒŒì¼ ë¹„ë°€ë²ˆí˜¸ í¬ë˜ì»¤ì…ë‹ˆë‹¤. CUDA ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ ë¹ ë¥¸ ì†ë„ë¡œ ZIP íŒŒì¼ì˜ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- NVIDIA CUDAë¥¼ í™œìš©í•œ GPU ë³‘ë ¬ ì²˜ë¦¬
- ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- ìë™ ë¡œê·¸ ê¸°ë¡
- ë©€í‹°ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
- ìƒì„¸í•œ GPU ì‚¬ìš© í˜„í™© í‘œì‹œ

## âš™ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- Windows 10/11
- NVIDIA GPU (CUDA ì§€ì›)
- Python 3.8 ì´ìƒ
- Visual Studio 2019 ë˜ëŠ” 2022 (C++ ë¹Œë“œ ë„êµ¬ í¬í•¨)
- NVIDIA CUDA Toolkit 11.0 ì´ìƒ

## ğŸ“¥ ì„¤ì¹˜ ë°©ë²•

1. **Python ì„¤ì¹˜**
   - [Python ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://www.python.org/downloads/)ì—ì„œ Python 3.8 ì´ìƒ ë²„ì „ ì„¤ì¹˜
   - ì„¤ì¹˜ ì‹œ "Add Python to PATH" ì˜µì…˜ ì²´í¬

2. **Visual Studio ì„¤ì¹˜**
   - [Visual Studio ë‹¤ìš´ë¡œë“œ](https://visualstudio.microsoft.com/downloads/)
   - "Desktop development with C++" ì›Œí¬ë¡œë“œ ì„ íƒ ì„¤ì¹˜
   ```powershell
   # ì„¤ì¹˜ í™•ì¸
   cl.exe
   ```

3. **CUDA Toolkit ì„¤ì¹˜**
   - [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
   ```powershell
   # ì„¤ì¹˜ í™•ì¸
   nvcc --version
   ```

4. **í”„ë¡œì íŠ¸ í´ë¡  ë° ì˜ì¡´ì„± ì„¤ì¹˜**
   ```bash
   git clone https://github.com/your-username/gpu-zip-cracker.git
   cd gpu-zip-cracker
   python -m venv venv
   .\venv\Scripts\activate
   pip install -r requirements.txt
   ```

## ğŸ’» ì‚¬ìš© ë°©ë²•

1. **í™˜ê²½ ì¤€ë¹„**
   - ë¹„ë°€ë²ˆí˜¸ë¥¼ ì°¾ì„ ZIP íŒŒì¼ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
   - ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
   ```bash
   .\venv\Scripts\activate
   ```

2. **ì½”ë“œ ì„¤ì •**
   - `zip_path` ë³€ìˆ˜ë¥¼ ë³¸ì¸ì˜ ZIP íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.
   ```python
   zip_path = r"C:\Path\To\Your\File.zip"  # ë³¸ì¸ì˜ ZIP íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •
   ```
   
   - í•„ìš”í•œ ê²½ìš° `charset` ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ê²€ìƒ‰í•  ë¬¸ìì…‹ì„ ì¡°ì •í•©ë‹ˆë‹¤.
   ```python
   charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*()-_=+[{]}|;:'\",<.>/?"
   ```

3. **ì‹¤í–‰**
   ```bash
   python password_cracker.py
   ```

4. **ë¡œê·¸ í™•ì¸**
   - í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹œ ìƒì„±ë˜ëŠ” `logs` í´ë”ì—ì„œ ìƒì„¸ ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   - ì½˜ì†”ì—ì„œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“Š GPUë³„ ì„±ëŠ¥ ìµœì í™” ì„¤ì •

ê° GPU ì‹œë¦¬ì¦ˆë³„ ê¶Œì¥ ì„¤ì •ê°’ì…ë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ì— ë”°ë¼ ë¯¸ì„¸ ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### GTX 10 ì‹œë¦¬ì¦ˆ
```python
# GTX 1060 (6GB)
self.threads_per_block = 256
self.blocks = 4096
self.num_streams = 2
self.buffer_multiplier = 1

# GTX 1070 (8GB)
self.threads_per_block = 512
self.blocks = 6144
self.num_streams = 2
self.buffer_multiplier = 1

# GTX 1080 / 1080 Ti (8GB/11GB)
self.threads_per_block = 512
self.blocks = 8192
self.num_streams = 3
self.buffer_multiplier = 2
```

### RTX 20 ì‹œë¦¬ì¦ˆ
```python
# RTX 2060 (6GB)
self.threads_per_block = 512
self.blocks = 6144
self.num_streams = 2
self.buffer_multiplier = 1

# RTX 2070 (8GB)
self.threads_per_block = 512
self.blocks = 8192
self.num_streams = 3
self.buffer_multiplier = 2

# RTX 2080 / 2080 Ti (8GB/11GB)
self.threads_per_block = 1024
self.blocks = 8192
self.num_streams = 3
self.buffer_multiplier = 2
```

### RTX 30 ì‹œë¦¬ì¦ˆ
```python
# RTX 3060 (12GB)
self.threads_per_block = 512
self.blocks = 8192
self.num_streams = 3
self.buffer_multiplier = 2

# RTX 3070 (8GB)
self.threads_per_block = 1024
self.blocks = 8192
self.num_streams = 3
self.buffer_multiplier = 2

# RTX 3080 (10GB)
self.threads_per_block = 1024
self.blocks = 12288
self.num_streams = 4
self.buffer_multiplier = 2

# RTX 3090 (24GB)
self.threads_per_block = 1024
self.blocks = 16384
self.num_streams = 4
self.buffer_multiplier = 2
```

### RTX 40 ì‹œë¦¬ì¦ˆ
```python
# RTX 4060 (8GB)
self.threads_per_block = 512
self.blocks = 8192
self.num_streams = 3
self.buffer_multiplier = 2

# RTX 4070 (12GB)
self.threads_per_block = 1024
self.blocks = 12288
self.num_streams = 4
self.buffer_multiplier = 2

# RTX 4080 (16GB)
self.threads_per_block = 1024
self.blocks = 16384
self.num_streams = 4
self.buffer_multiplier = 2

# RTX 4090 (24GB)
self.threads_per_block = 1024
self.blocks = 24576
self.num_streams = 6
self.buffer_multiplier = 3
```

### ìµœì í™” ê°€ì´ë“œë¼ì¸

1. **ë©”ëª¨ë¦¬ ê´€ë ¨**
   - `blocks` Ã— `threads_per_block` Ã— `buffer_multiplier` Ã— 15bytesê°€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì˜ ì£¼ìš” ìš”ì†Œì…ë‹ˆë‹¤
   - GPU ë©”ëª¨ë¦¬ì˜ 80% ì´ë‚´ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤
   - ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ë°œìƒ ì‹œ ìš°ì„ ì ìœ¼ë¡œ `blocks` ê°’ì„ ì¤„ì´ì„¸ìš”

2. **ì„±ëŠ¥ ê´€ë ¨**
   - `threads_per_block`ì€ GPU ì•„í‚¤í…ì²˜ì˜ ì›Œí”„ í¬ê¸°(32)ì˜ ë°°ìˆ˜ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤
   - GPU ì‚¬ìš©ë¥ ì´ ë‚®ì„ ê²½ìš° `num_streams` ê°’ì„ ì¦ê°€ì‹œì¼œ ë³´ì„¸ìš”
   - ìµœì‹  GPUì¼ìˆ˜ë¡ ë” í° `threads_per_block` ê°’ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

3. **ë°œì—´ ê´€ë ¨**
   - ê³¼ë„í•œ `num_streams` ê°’ì€ GPU ë°œì—´ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤
   - ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ `buffer_multiplier` ê°’ì„ ë‚®ì¶”ëŠ” ê²ƒì´ ì•ˆì •ì„±ì— ë„ì›€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤

4. **ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸**
```python
def get_optimal_settings(gpu_name):
    gpu_name = gpu_name.lower()
    
    # ê¸°ë³¸ê°’ (ì•ˆì „í•œ ì„¤ì •)
    settings = {
        'threads_per_block': 256,
        'blocks': 4096,
        'num_streams': 2,
        'buffer_multiplier': 1
    }
    
    # GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ì„¤ì • ì¡°ì •
    memory_gb = get_gpu_memory()  # GPU ë©”ëª¨ë¦¬ í¬ê¸° (GB)
    
    if memory_gb >= 20:  # 3090, 4090 ë“± ê³ ìš©ëŸ‰
        settings.update({
            'threads_per_block': 1024,
            'blocks': 16384,
            'num_streams': 4,
            'buffer_multiplier': 2
        })
    elif memory_gb >= 10:  # 3080, 4080 ë“± ì¤‘ìƒê¸‰
        settings.update({
            'threads_per_block': 1024,
            'blocks': 12288,
            'num_streams': 4,
            'buffer_multiplier': 2
        })
    elif memory_gb >= 8:  # 3070, 2080 ë“± ì¤‘ê¸‰
        settings.update({
            'threads_per_block': 512,
            'blocks': 8192,
            'num_streams': 3,
            'buffer_multiplier': 2
        })
    
    return settings
```

ì£¼ì˜: ìœ„ ì„¤ì •ê°’ë“¤ì€ ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ì„±ëŠ¥ì€ ì‹œìŠ¤í…œ í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì§„ì ìœ¼ë¡œ ê°’ì„ ì¡°ì •í•˜ë©´ì„œ ìµœì ì˜ ì„¤ì •ì„ ì°¾ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

## ğŸ” ë¬¸ì œ í•´ê²°

1. **CUDA ì´ˆê¸°í™” ì‹¤íŒ¨**
   ```
   ERROR: CUDA driver version is insufficient for CUDA runtime version
   ```
   - NVIDIA ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸ í•„ìš”
   - CUDA Toolkit ì¬ì„¤ì¹˜ ì‹œë„

2. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**
   ```
   ERROR: out of memory
   ```
   - `blocks` ê°’ì„ ì¤„ì—¬ì„œ ì‹œë„
   - ë‹¤ë¥¸ GPU í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í›„ ì‹œë„

3. **ì»´íŒŒì¼ëŸ¬ ì˜¤ë¥˜**
   ```
   ERROR: Microsoft Visual C++ 14.0 or greater is required
   ```
   - Visual Studio C++ ë¹Œë“œ ë„êµ¬ ì„¤ì¹˜ í•„ìš”

4. **CUDA í˜¸í™˜ì„± ë¬¸ì œ**
   - NVIDIA GPU ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸
   - CUDA Toolkit ë²„ì „ í™•ì¸
   - Visual Studio ë²„ì „ í˜¸í™˜ì„± í™•ì¸

## ğŸ“ ë¼ì´ì„ ìŠ¤

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## âš ï¸ ì£¼ì˜ì‚¬í•­

- ë³¸ ë„êµ¬ëŠ” í•©ë²•ì ì¸ ìš©ë„ë¡œë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
- ìì‹ ì˜ íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš° ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- GPU ê³¼ë¶€í•˜ì— ì£¼ì˜í•˜ì„¸ìš”.
- ì •ê¸°ì ìœ¼ë¡œ GPU ì˜¨ë„ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request
